{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import layers,applications\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n# to not get tensed over unnecessary warning we will ignore them\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:06:35.015490Z","iopub.execute_input":"2021-12-23T20:06:35.015836Z","iopub.status.idle":"2021-12-23T20:06:35.027662Z","shell.execute_reply.started":"2021-12-23T20:06:35.015806Z","shell.execute_reply":"2021-12-23T20:06:35.026626Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# specifying the image size we want to input in model\npicture_size=48","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:06:41.234747Z","iopub.execute_input":"2021-12-23T20:06:41.235305Z","iopub.status.idle":"2021-12-23T20:06:41.240877Z","shell.execute_reply.started":"2021-12-23T20:06:41.235273Z","shell.execute_reply":"2021-12-23T20:06:41.239603Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# specifying the path where the data is stored\nfolder_path = ('../input/fer2013')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:06:44.802834Z","iopub.execute_input":"2021-12-23T20:06:44.803097Z","iopub.status.idle":"2021-12-23T20:06:44.807807Z","shell.execute_reply.started":"2021-12-23T20:06:44.803067Z","shell.execute_reply":"2021-12-23T20:06:44.806764Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# lsit of all classes\nclasses = ['angry','disgust','fear','happy','neutral','sad','surprise']","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:06:49.221300Z","iopub.execute_input":"2021-12-23T20:06:49.221945Z","iopub.status.idle":"2021-12-23T20:06:49.227449Z","shell.execute_reply.started":"2021-12-23T20:06:49.221910Z","shell.execute_reply":"2021-12-23T20:06:49.225908Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# viewing some of the images from each category\nplt.figure(figsize= (12,12))\ni=1\nfor category in classes:\n    for j in range(1,5):\n        plt.subplot(7,4,i)\n        img = load_img(\"../input/fer2013/train/\"+category+\"/\"+\n                  os.listdir(\"../input/fer2013/train/\" + category)[j], target_size=(picture_size, picture_size))\n    plt.imshow(img)\n    i+=1\n    print(category) \nplt.show()\nx=img_to_array(img)\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:07:18.193075Z","iopub.execute_input":"2021-12-23T20:07:18.193450Z","iopub.status.idle":"2021-12-23T20:07:18.995219Z","shell.execute_reply.started":"2021-12-23T20:07:18.193419Z","shell.execute_reply":"2021-12-23T20:07:18.994229Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# finding the count of images in each category\ncategory=[]\nexamples=[]\nfor i in classes:\n    dir='../input/fer2013/train/'+i\n    onlyfiles = next(os.walk(dir))[2] #dir is your directory path as string\n    category.append(i)\n    examples.append(len(onlyfiles))","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:09:33.560022Z","iopub.execute_input":"2021-12-23T20:09:33.560547Z","iopub.status.idle":"2021-12-23T20:09:36.745411Z","shell.execute_reply.started":"2021-12-23T20:09:33.560512Z","shell.execute_reply":"2021-12-23T20:09:36.744462Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"# creating a dataframe for the count of images\nexample_count_df=pd.DataFrame(category,columns=['Category'],index=[1,2,3,4,5,6,7])\nexample_count_df['No. of images']=examples\nexample_count_df","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:09:45.404172Z","iopub.execute_input":"2021-12-23T20:09:45.404537Z","iopub.status.idle":"2021-12-23T20:09:45.441944Z","shell.execute_reply.started":"2021-12-23T20:09:45.404503Z","shell.execute_reply":"2021-12-23T20:09:45.440801Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# visualizing\nplt.figure(figsize=(8,8))\nsns.barplot(x=example_count_df['Category'],y=example_count_df['No. of images'])\nplt.title('Count of images in each category',fontsize=20)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:10:02.579843Z","iopub.execute_input":"2021-12-23T20:10:02.580196Z","iopub.status.idle":"2021-12-23T20:10:02.875825Z","shell.execute_reply.started":"2021-12-23T20:10:02.580140Z","shell.execute_reply":"2021-12-23T20:10:02.874877Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# defining the train and test set \nbatch_size  = 128\n\ndatagen_train  = ImageDataGenerator(rescale=1./255,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True)\ndatagen_val = ImageDataGenerator(rescale=1./255)\n\ntrain_set = datagen_train.flow_from_directory(\"../input/fer2013/train\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=True)\n\n\ntest_set = datagen_val.flow_from_directory(\"../input/fer2013/test\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:12:09.007567Z","iopub.execute_input":"2021-12-23T20:12:09.007881Z","iopub.status.idle":"2021-12-23T20:12:15.521108Z","shell.execute_reply.started":"2021-12-23T20:12:09.007851Z","shell.execute_reply":"2021-12-23T20:12:15.519801Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# defining a CNN model\nno_of_classes = 7\n\nmodel = Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\n\nopt = Adam(lr = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:12:26.862632Z","iopub.execute_input":"2021-12-23T20:12:26.862916Z","iopub.status.idle":"2021-12-23T20:12:27.193656Z","shell.execute_reply.started":"2021-12-23T20:12:26.862885Z","shell.execute_reply":"2021-12-23T20:12:27.192713Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# defining a callback that will save the best model\ncheckpoint = ModelCheckpoint(\"model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\ncallbacks_list = [checkpoint]\n\n# defining no. of epoch\nepochs = 50\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:13:03.870282Z","iopub.execute_input":"2021-12-23T20:13:03.870572Z","iopub.status.idle":"2021-12-23T20:13:03.884308Z","shell.execute_reply.started":"2021-12-23T20:13:03.870542Z","shell.execute_reply":"2021-12-23T20:13:03.883119Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# Fitting and training the model\nhistory = model.fit(train_set,\n                        epochs=epochs,\n                        validation_data = test_set,\n                        callbacks=callbacks_list\n                        )","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:13:08.833652Z","iopub.execute_input":"2021-12-23T20:13:08.834258Z","iopub.status.idle":"2021-12-23T20:46:20.076460Z","shell.execute_reply.started":"2021-12-23T20:13:08.834226Z","shell.execute_reply":"2021-12-23T20:46:20.075383Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"# loading the saved model\ntrained_model=load_model('model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:46:32.070984Z","iopub.execute_input":"2021-12-23T20:46:32.071805Z","iopub.status.idle":"2021-12-23T20:46:32.803071Z","shell.execute_reply.started":"2021-12-23T20:46:32.071769Z","shell.execute_reply":"2021-12-23T20:46:32.802036Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"# evaluating the train set\ntrained_model.evaluate(train_set)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:46:47.641438Z","iopub.execute_input":"2021-12-23T20:46:47.641757Z","iopub.status.idle":"2021-12-23T20:47:29.031439Z","shell.execute_reply.started":"2021-12-23T20:46:47.641728Z","shell.execute_reply":"2021-12-23T20:47:29.028605Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# evaluating the test set\ntrained_model.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:48:13.877134Z","iopub.execute_input":"2021-12-23T20:48:13.877466Z","iopub.status.idle":"2021-12-23T20:48:19.791633Z","shell.execute_reply.started":"2021-12-23T20:48:13.877434Z","shell.execute_reply":"2021-12-23T20:48:19.790546Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# plotting the Loss for training and validation set\nplt.figure(figsize=(15,8))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\n# plotting the Accuracy for training and validation set\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:48:43.665097Z","iopub.execute_input":"2021-12-23T20:48:43.665488Z","iopub.status.idle":"2021-12-23T20:48:44.082811Z","shell.execute_reply.started":"2021-12-23T20:48:43.665442Z","shell.execute_reply":"2021-12-23T20:48:44.081921Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:49:46.409398Z","iopub.execute_input":"2021-12-23T20:49:46.409706Z","iopub.status.idle":"2021-12-23T20:49:46.445292Z","shell.execute_reply.started":"2021-12-23T20:49:46.409663Z","shell.execute_reply":"2021-12-23T20:49:46.444305Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"test_examples = ['../input/test-image/Fear.jpg',\n                 '../input/test-image/angry.jpg',\n                '../input/test-image/disgust.jpg',\n                '../input/test-image/happy.jpg',\n                '../input/test-image/neutral.jpg',\n                '../input/test-image/sad.jpg',\n                '../input/test-image/surprise.jpg']","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:53:56.667128Z","iopub.execute_input":"2021-12-23T20:53:56.667457Z","iopub.status.idle":"2021-12-23T20:53:56.672868Z","shell.execute_reply.started":"2021-12-23T20:53:56.667425Z","shell.execute_reply":"2021-12-23T20:53:56.671896Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# view these images\nplt.figure(figsize=(30,12))\nfor i,j in enumerate(test_examples):\n    frame=cv2.imread(j)\n    plt.subplot(3,5,i+1)\n    plt.title(j)\n    plt.imshow(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:53:59.792079Z","iopub.execute_input":"2021-12-23T20:53:59.792732Z","iopub.status.idle":"2021-12-23T20:54:01.547831Z","shell.execute_reply.started":"2021-12-23T20:53:59.792695Z","shell.execute_reply":"2021-12-23T20:54:01.544675Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# defining emotion labels\nemotion_labels = ['Angry','Disgust','Fear','Happy','Neutral', 'Sad', 'Surprise']","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:54:10.183705Z","iopub.execute_input":"2021-12-23T20:54:10.183986Z","iopub.status.idle":"2021-12-23T20:54:10.190658Z","shell.execute_reply.started":"2021-12-23T20:54:10.183955Z","shell.execute_reply":"2021-12-23T20:54:10.189629Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# making predictions\nfor i in test_examples:\n    frame=cv2.imread(i)\n    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n    faces = faceCascade.detectMultiScale(gray)\n\n    for (x,y,w,h) in faces:\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n        roi_gray = gray[y:y+h,x:x+w]\n        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n\n        if np.sum([roi_gray])!=0:\n            roi = roi_gray.astype('float')/255.0\n            roi = img_to_array(roi)\n            roi = np.expand_dims(roi,axis=0)\n\n            prediction = trained_model.predict(roi)[0]\n            label=emotion_labels[prediction.argmax()]\n            label_position = (x,y)\n            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n        else:\n            cv2.putText(frame,'No Faces',(30,80),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    plt.show()\n    #cv2.imshow(frame)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T20:55:15.940263Z","iopub.execute_input":"2021-12-23T20:55:15.940559Z","iopub.status.idle":"2021-12-23T20:55:18.513432Z","shell.execute_reply.started":"2021-12-23T20:55:15.940528Z","shell.execute_reply":"2021-12-23T20:55:18.512394Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}