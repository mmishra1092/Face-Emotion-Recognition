{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-23T15:50:56.837595Z","iopub.execute_input":"2021-12-23T15:50:56.838349Z","iopub.status.idle":"2021-12-23T15:51:10.256986Z","shell.execute_reply.started":"2021-12-23T15:50:56.838242Z","shell.execute_reply":"2021-12-23T15:51:10.256224Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import layers,applications\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n# to not get tensed over unnecessary warning we will ignore them\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T17:37:42.895477Z","iopub.execute_input":"2021-12-23T17:37:42.895858Z","iopub.status.idle":"2021-12-23T17:37:49.840739Z","shell.execute_reply.started":"2021-12-23T17:37:42.895816Z","shell.execute_reply":"2021-12-23T17:37:49.839692Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# specifying the image size we want to input in model\npicture_size=48","metadata":{"execution":{"iopub.status.busy":"2021-12-23T17:56:28.890772Z","iopub.execute_input":"2021-12-23T17:56:28.891051Z","iopub.status.idle":"2021-12-23T17:56:28.896413Z","shell.execute_reply.started":"2021-12-23T17:56:28.891020Z","shell.execute_reply":"2021-12-23T17:56:28.895103Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# specifying the path where the data is stored\nfolder_path = ('../input/fer2013')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T17:56:33.843440Z","iopub.execute_input":"2021-12-23T17:56:33.843725Z","iopub.status.idle":"2021-12-23T17:56:33.848596Z","shell.execute_reply.started":"2021-12-23T17:56:33.843692Z","shell.execute_reply":"2021-12-23T17:56:33.847322Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# lsit of all classes\nclasses = ['angry','disgust','fear','happy','neutral','sad','surprise']","metadata":{"execution":{"iopub.status.busy":"2021-12-23T17:58:39.066783Z","iopub.execute_input":"2021-12-23T17:58:39.067109Z","iopub.status.idle":"2021-12-23T17:58:39.071931Z","shell.execute_reply.started":"2021-12-23T17:58:39.067074Z","shell.execute_reply":"2021-12-23T17:58:39.070941Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# viewing some of the images from each category\nplt.figure(figsize= (12,12))\ni=1\nfor category in classes:\n    for j in range(1,5):\n        plt.subplot(7,4,i)\n        img = load_img(\"../input/fer2013/train/\"+category+\"/\"+\n                  os.listdir(\"../input/fer2013/train/\" + category)[j], target_size=(picture_size, picture_size))\n    plt.imshow(img)\n    i+=1\n    print(category) \nplt.show()\nx=img_to_array(img)\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T17:58:40.990850Z","iopub.execute_input":"2021-12-23T17:58:40.991560Z","iopub.status.idle":"2021-12-23T17:58:41.835444Z","shell.execute_reply.started":"2021-12-23T17:58:40.991522Z","shell.execute_reply":"2021-12-23T17:58:41.834381Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# finding the count of images in each category\ncategory=[]\nexamples=[]\nfor i in classes:\n    dir='../input/fer2013/train/'+i\n    onlyfiles = next(os.walk(dir))[2] #dir is your directory path as string\n    category.append(i)\n    examples.append(len(onlyfiles))","metadata":{"execution":{"iopub.status.busy":"2021-12-23T17:58:43.917034Z","iopub.execute_input":"2021-12-23T17:58:43.917673Z","iopub.status.idle":"2021-12-23T17:58:47.374665Z","shell.execute_reply.started":"2021-12-23T17:58:43.917635Z","shell.execute_reply":"2021-12-23T17:58:47.373750Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# creating a dataframe for the count of images\nexample_count_df=pd.DataFrame(category,columns=['Category'],index=[1,2,3,4,5,6,7])\nexample_count_df['No. of images']=examples\nexample_count_df","metadata":{"execution":{"iopub.status.busy":"2021-12-23T17:58:49.240046Z","iopub.execute_input":"2021-12-23T17:58:49.240784Z","iopub.status.idle":"2021-12-23T17:58:49.255940Z","shell.execute_reply.started":"2021-12-23T17:58:49.240748Z","shell.execute_reply":"2021-12-23T17:58:49.254617Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# visualizing\nplt.figure(figsize=(8,8))\nsns.barplot(x=example_count_df['Category'],y=example_count_df['No. of images'])\nplt.title('Count of images in each category',fontsize=20)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T17:58:52.283284Z","iopub.execute_input":"2021-12-23T17:58:52.283566Z","iopub.status.idle":"2021-12-23T17:58:52.582587Z","shell.execute_reply.started":"2021-12-23T17:58:52.283533Z","shell.execute_reply":"2021-12-23T17:58:52.581657Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# defining the train and test set \nbatch_size  = 128\n\ndatagen_train  = ImageDataGenerator(rescale=1./255,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True)\ndatagen_val = ImageDataGenerator(rescale=1./255)\n\ntrain_set = datagen_train.flow_from_directory(\"../input/fer2013/train\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=True)\n\n\ntest_set = datagen_val.flow_from_directory(\"../input/fer2013/test\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T18:04:29.196246Z","iopub.execute_input":"2021-12-23T18:04:29.196776Z","iopub.status.idle":"2021-12-23T18:04:36.057672Z","shell.execute_reply.started":"2021-12-23T18:04:29.196744Z","shell.execute_reply":"2021-12-23T18:04:36.056585Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# defining a CNN model\nno_of_classes = 7\n\nmodel = Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\n\nopt = Adam(lr = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T18:05:19.771019Z","iopub.execute_input":"2021-12-23T18:05:19.771834Z","iopub.status.idle":"2021-12-23T18:05:20.030038Z","shell.execute_reply.started":"2021-12-23T18:05:19.771797Z","shell.execute_reply":"2021-12-23T18:05:20.028941Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# defining a callback that will save the best model\ncheckpoint = ModelCheckpoint(\"model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\ncallbacks_list = [checkpoint]\n\n# defining no. of epoch\nepochs = 48\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T18:05:39.477094Z","iopub.execute_input":"2021-12-23T18:05:39.477675Z","iopub.status.idle":"2021-12-23T18:05:39.492586Z","shell.execute_reply.started":"2021-12-23T18:05:39.477638Z","shell.execute_reply":"2021-12-23T18:05:39.491575Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Fitting and training the model\nhistory = model.fit(train_set,\n                        epochs=epochs,\n                        validation_data = test_set,\n                        callbacks=callbacks_list\n                        )","metadata":{"execution":{"iopub.status.busy":"2021-12-23T18:05:43.475805Z","iopub.execute_input":"2021-12-23T18:05:43.476114Z","iopub.status.idle":"2021-12-23T18:40:24.561782Z","shell.execute_reply.started":"2021-12-23T18:05:43.476083Z","shell.execute_reply":"2021-12-23T18:40:24.560675Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# loading the saved model\ntrained_model=load_model('model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T18:49:00.463127Z","iopub.execute_input":"2021-12-23T18:49:00.463858Z","iopub.status.idle":"2021-12-23T18:49:00.854708Z","shell.execute_reply.started":"2021-12-23T18:49:00.463823Z","shell.execute_reply":"2021-12-23T18:49:00.853719Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# evaluating the train set\ntrained_model.evaluate(train_set)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T18:49:06.629385Z","iopub.execute_input":"2021-12-23T18:49:06.629960Z","iopub.status.idle":"2021-12-23T18:49:48.011286Z","shell.execute_reply.started":"2021-12-23T18:49:06.629922Z","shell.execute_reply":"2021-12-23T18:49:48.010201Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# evaluating the test set\ntrained_model.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T18:49:57.882823Z","iopub.execute_input":"2021-12-23T18:49:57.883145Z","iopub.status.idle":"2021-12-23T18:50:04.133343Z","shell.execute_reply.started":"2021-12-23T18:49:57.883102Z","shell.execute_reply":"2021-12-23T18:50:04.132251Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# plotting the Loss for training and validation set\nplt.figure(figsize=(15,8))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\n# plotting the Accuracy for training and validation set\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T18:50:22.323093Z","iopub.execute_input":"2021-12-23T18:50:22.323412Z","iopub.status.idle":"2021-12-23T18:50:22.752004Z","shell.execute_reply.started":"2021-12-23T18:50:22.323379Z","shell.execute_reply":"2021-12-23T18:50:22.750982Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')","metadata":{"execution":{"iopub.status.busy":"2021-12-23T18:55:11.476769Z","iopub.execute_input":"2021-12-23T18:55:11.477049Z","iopub.status.idle":"2021-12-23T18:55:11.510703Z","shell.execute_reply.started":"2021-12-23T18:55:11.477019Z","shell.execute_reply":"2021-12-23T18:55:11.509715Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"test_examples = ['../input/test-image/Fear.jpg',\n                 '../input/test-image/angry.jpg',\n                '../input/test-image/disgust.jpg',\n                '../input/test-image/happy.jpg',\n                '../input/test-image/neutral.jpg',\n                '../input/test-image/sad.jpg',\n                '../input/test-image/surprise.jpg']","metadata":{"execution":{"iopub.status.busy":"2021-12-23T19:32:20.234082Z","iopub.execute_input":"2021-12-23T19:32:20.234461Z","iopub.status.idle":"2021-12-23T19:32:20.240618Z","shell.execute_reply.started":"2021-12-23T19:32:20.234429Z","shell.execute_reply":"2021-12-23T19:32:20.239252Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# view these images\nplt.figure(figsize=(30,15))\nfor i,j in enumerate(test_examples):\n    frame=cv2.imread(j)\n    plt.subplot(3,5,i+1)\n    plt.title(j)\n    plt.imshow(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))","metadata":{"execution":{"iopub.status.busy":"2021-12-23T19:32:21.526810Z","iopub.execute_input":"2021-12-23T19:32:21.527092Z","iopub.status.idle":"2021-12-23T19:32:23.034836Z","shell.execute_reply.started":"2021-12-23T19:32:21.527060Z","shell.execute_reply":"2021-12-23T19:32:23.032040Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# defining emotion labels\nemotion_labels = ['Angry','Disgust','Fear','Happy','Neutral', 'Sad', 'Surprise']","metadata":{"execution":{"iopub.status.busy":"2021-12-23T19:32:41.785406Z","iopub.execute_input":"2021-12-23T19:32:41.785694Z","iopub.status.idle":"2021-12-23T19:32:41.791448Z","shell.execute_reply.started":"2021-12-23T19:32:41.785664Z","shell.execute_reply":"2021-12-23T19:32:41.789991Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# making predictions\nfor i in test_examples:\n    frame=cv2.imread(i)\n    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n    faces = faceCascade.detectMultiScale(gray)\n\n    for (x,y,w,h) in faces:\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n        roi_gray = gray[y:y+h,x:x+w]\n        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n\n        if np.sum([roi_gray])!=0:\n            roi = roi_gray.astype('float')/255.0\n            roi = img_to_array(roi)\n            roi = np.expand_dims(roi,axis=0)\n\n            prediction = trained_model.predict(roi)[0]\n            label=emotion_labels[prediction.argmax()]\n            label_position = (x,y)\n            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n        else:\n            cv2.putText(frame,'No Faces',(30,80),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    plt.show()\n    #cv2.imshow(frame)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T19:32:48.484549Z","iopub.execute_input":"2021-12-23T19:32:48.484832Z","iopub.status.idle":"2021-12-23T19:32:50.678873Z","shell.execute_reply.started":"2021-12-23T19:32:48.484801Z","shell.execute_reply":"2021-12-23T19:32:50.677894Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}